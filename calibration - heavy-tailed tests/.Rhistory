library(dendextend)  # plotting helpers for dendrograms
library(lsa)         # cosine() similarity
})
# Config
label_col <- "Metadata_Compound_type"
install.packages("lsa")
# Packages
suppressPackageStartupMessages({
library(dendextend)  # plotting helpers for dendrograms
library(lsa)         # cosine() similarity
})
# Config
label_col <- "Metadata_Compound_type"
count_col <- "Metadata_Object_Count"
k_mad     <- 2             # toxicity threshold = median - 2 * MAD (from DMSO)
k         <- 5             # number of clusters for cutree
pcs_to_use <- paste0("PC", 1:24)
stopifnot(all(c("Label", pcs_to_use) %in% names(pc_scores_k90)))
# (Optional) Subsample to keep N×N cosine matrix manageable
set.seed(123)
MAX_N <- 20000
n_all <- nrow(pc_scores_k90)
idx   <- if (n_all > MAX_N) sample.int(n_all, MAX_N) else seq_len(n_all)
# Data matrix for clustering (rows = samples, cols = PCs)
X <- as.matrix(pc_scores_k90[idx, pcs_to_use, drop = FALSE])
# Cosine similarity & distance
# lsa::cosine expects variables in columns; we want pairwise between rows -> transpose
cos_sim  <- cosine(t(X))       # N x N similarity in [-1, 1]
MAX_N <- 10000
n_all <- nrow(pc_scores_k90)
idx   <- if (n_all > MAX_N) sample.int(n_all, MAX_N) else seq_len(n_all)
# Data matrix for clustering (rows = samples, cols = PCs)
X <- as.matrix(pc_scores_k90[idx, pcs_to_use, drop = FALSE])
# Cosine similarity & distance
# lsa::cosine expects variables in columns; we want pairwise between rows -> transpose
cos_sim  <- cosine(t(X))       # N x N similarity in [-1, 1]
cos_dist <- as.dist(1 - cos_sim)
# Agglomerative HC (average linkage)
hc_cos <- hclust(cos_dist, method = "average")
clusters <- cutree(hc_cos, k = k)  # factor later
# DMSO-based toxicity threshold (median - 2*MAD) computed from ORIGINAL data
x_all <- data[[count_col]]
if (!is.numeric(x_all)) x_all <- suppressWarnings(as.numeric(x_all))
labels_all <- as.character(data[[label_col]])
x_dmso <- x_all[labels_all == "DMSO"]
x_dmso <- x_dmso[!is.na(x_dmso)]
thr_med_mad <- median(x_dmso, na.rm = TRUE) - k_mad * mad(x_dmso, na.rm = TRUE)
cat(sprintf("DMSO threshold (median - %d*MAD): %.3f\n", k_mad, thr_med_mad))
# Build aligned dataframe for the clustered rows (same idx)
df <- data.frame(
Cluster = factor(clusters, levels = 1:k),
Label   = as.character(pc_scores_k90$Label[idx]),
stringsAsFactors = FALSE
)
# Normalize spelling
df$Label[df$Label == "Tetradrine"] <- "Tetrandrine"
# Attach counts aligned to same rows used in clustering
if (count_col %in% names(pc_scores_k90)) {
df$Count <- as.numeric(pc_scores_k90[[count_col]][idx])
} else if (exists("data_new") && exists("cc") && is.logical(cc) && length(cc) == nrow(data_new)) {
df$Count <- as.numeric(data_new[cc, count_col][idx])
} else {
stop("Cannot find aligned counts. Include 'Metadata_Object_Count' in pc_scores_k90 or keep data_new+cc.")
}
# Split EOS into two categories by the threshold
df$Category <- df$Label
df$Category[df$Label == "EOS" & df$Count <  thr_med_mad] <- "EOS (< thr)"
df$Category[df$Label == "EOS" & df$Count >= thr_med_mad] <- "EOS (>= thr)"
df$Category <- factor(df$Category,
levels = c("DMSO", "Nocodazole", "Tetrandrine", "EOS (< thr)", "EOS (>= thr)")
)
# Composition tables
tab <- table(df$Cluster, df$Category)
# 1) Within-cluster composition (row-wise %, sums to 100 across columns)
pct_within <- round(prop.table(tab, margin = 1) * 100, 1)
pct_within_df <- as.data.frame.matrix(pct_within)
cat("\n% of each cluster (row-wise composition):\n")
print(pct_within_df)
# 2) Cluster capture rate (column-wise %, sums to 100 down rows)
pct_capture <- round(prop.table(tab, margin = 2) * 100, 1)
pct_capture_df <- as.data.frame.matrix(pct_capture)
cat("\n% of each category captured by clusters (column-wise %):\n")
print(pct_capture_df)
#####Read Data#####
data <- read.csv("/Users/cparijat/Downloads/STATS_604/openscreen.csv", header = TRUE, stringsAsFactors = FALSE)
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/utils.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/utils.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
cor.type<- "exch"
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
# Calibration heatmaps
calibration.heatmaps(n=1e6,d=10,nu.vec = c(0.1,0.5, 1, 5, 15, 30),
cor.type = "exch")
get.cor <- function(d, rho=0.5, cor.type="exch") {
stopifnot(cor.type %in% c("exch", "autoreg", "diag"))
if (cor.type=="exch") {
cor.mat <- matrix(rep(rho, d*d), nrow=d)
diag(cor.mat) <- 1
}
else if (cor.type=="autoreg") {
cor.mat <- rho^(abs(outer(1:d, 1:d, FUN="-")))
} else if (cor.type=="diag") {
cor.mat <- diag(d)
}
return(cor.mat)
}
# ----- Calibration Line Plot -----
calibration.lineplot <- function(nu.vec = c(1, 30),
alpha.vec = 10^seq(log10(0.001), log10(0.1), length.out = 100),
d = 10, n = 1e6,
cor.type = "autoreg") {
par(mfrow = c(1, length(nu.vec)), mar = c(4, 4, 3, 1), oma = c(0, 0, 4, 0))
for (nu in nu.vec) {
message(sprintf("Running nu = %f", nu))
cor.mat <- get.cor(d, cor.type = cor.type)
# simulate under null (mu = 0)
X <- mvrnorm(n = n, mu = rep(0, d), Sigma = cor.mat)
denom <- replicate(n, sqrt(rgamma(n=1,shape = nu/2,rate = 1/2)/nu))
X <- X / denom
pval <- 1 - pt(X, df = nu)
rejections <- t(sapply(alpha.vec, function(alpha) {
p.pareto <- combine.test(pval, method = "Pareto")
p.cauchy <- combine.test(pval, method = "Cauchy")
c(mean(p.pareto < alpha), mean(p.cauchy < alpha))
}))
ratio <- rejections / alpha.vec
plot(1 / alpha.vec, ratio[,1], type = "l", col = "red", ylim=c(0, max(ratio)),
xlab=TeX("$1/\\alpha$"), ylab="Empirical Rejection Rate / alpha",
main=TeX(sprintf("ν = %.2f", nu)))
lines(1 / alpha.vec, ratio[,2], type = "l", col = "blue")
abline(h = 1, lty = 2)
legend("bottomright", legend=c("PCT", "CCT"), col=c("red", "blue"), pch=1)
}
mtext(
TeX(sprintf("Calibration of PCT & CCT under Multivariate-$t_\\nu(0,\\Sigma)$ with %s $\\Sigma$", cor.type)),
outer = TRUE, cex = 1.5, line = 1
)
par(mfrow = c(1, 1))
}
# ----- Calibration Heatmaps -----
calibration.heatmaps <- function(alpha.vec = c( 0.05, 0.01, 0.005,0.001,0.0005,0.0001),
nu.vec = c(1, 5, 15, 30),
d = 10, n = 1e6,
cor.type = "autoreg") {
mat.pareto <- matrix(NA, nrow = length(alpha.vec), ncol = length(nu.vec))
mat.cauchy <- matrix(NA, nrow = length(alpha.vec), ncol = length(nu.vec))
for (i in seq_along(nu.vec)) {
nu <- nu.vec[i]
cor.mat <- get.cor(d, rho=0.5,cor.type = cor.type)
# simulate null
X <- mvrnorm(n = n, mu = rep(0, d), Sigma = cor.mat)
denom <- replicate(n, sqrt(rgamma(n=1,shape = nu/2,rate = 1/2)/nu))
X <- X / denom
pval <- 1 - pt(X, df = nu)
for (j in seq_along(alpha.vec)) {
alpha <- alpha.vec[j]
mat.pareto[j, i] <- mean(combine.test(pval, method = "Pareto") < alpha) / alpha
mat.cauchy[j, i] <- mean(combine.test(pval, method = "Cauchy") < alpha) / alpha
}
}
df.pareto <- melt(mat.pareto)
df.cauchy <- melt(mat.cauchy)
colnames(df.pareto) <- colnames(df.cauchy) <- c("alpha.idx", "nu.idx", "ratio")
df.pareto$Method <- "Pareto"
df.cauchy$Method <- "Cauchy"
df <- rbind(df.pareto, df.cauchy)
df$alpha <- factor(alpha.vec[df$alpha.idx], levels = rev(alpha.vec))
df$nu <- factor(nu.vec[df$nu.idx])
gg <- ggplot(df, aes(x = nu, y = alpha, fill = ratio)) +
geom_tile(color = "white") +
scale_fill_gradient2(low = "blue", mid = "white", high = "red",
midpoint = 1,limits=c(0,2),
name = TeX("Empirical Rejection / $\\alpha$")) +
facet_wrap(~Method) +
labs(title = TeX(sprintf("Calibration Heatmaps for Multivariate-$t_\\nu(0,\\Sigma)$ with %s $\\Sigma$", cor.type)),
x = TeX("$\\nu$"), y = TeX("$\\alpha$")) +
theme_minimal(base_size = 13)
print(gg)
}
# Calibration heatmaps
calibration.heatmaps(n=1e6,d=10,nu.vec = c(0.1,0.5, 1, 5, 15, 30),
cor.type = "exch")
# ----- Calibration Heatmaps -----
calibration.heatmaps <- function(alpha.vec = c( 0.05, 0.01, 0.005,0.001,0.0005,0.0001),
nu.vec = c(1, 5, 15, 30),
d = 10, n = 1e6,
cor.type = "autoreg") {
mat.pareto <- matrix(NA, nrow = length(alpha.vec), ncol = length(nu.vec))
mat.cauchy <- matrix(NA, nrow = length(alpha.vec), ncol = length(nu.vec))
for (i in seq_along(nu.vec)) {
nu <- nu.vec[i]
cor.mat <- get.cor(d, rho=0.5,cor.type = cor.type)
# simulate null
X <- mvrnorm(n = n, mu = rep(0, d), Sigma = cor.mat)
denom <- replicate(n, sqrt(rgamma(n=1,shape = nu/2,rate = 1/2)/nu))
X <- X / denom
pval <- 1 - pt(X, df = nu)
for (j in seq_along(alpha.vec)) {
alpha <- alpha.vec[j]
mat.pareto[j, i] <- mean(combine.test(pval, method = "Pareto") < alpha) / alpha
mat.cauchy[j, i] <- mean(combine.test(pval, method = "Cauchy") < alpha) / alpha
}
}
df.pareto <- as.data.frame(as.table(mat.pareto))
df.cauchy <- as.data.frame(as.table(mat.cauchy))
colnames(df.pareto) <- colnames(df.cauchy) <- c("alpha.idx", "nu.idx", "ratio")
df.pareto$Method <- "Pareto"
df.cauchy$Method <- "Cauchy"
df <- rbind(df.pareto, df.cauchy)
df$alpha <- factor(alpha.vec[df$alpha.idx], levels = rev(alpha.vec))
df$nu <- factor(nu.vec[df$nu.idx])
gg <- ggplot(df, aes(x = nu, y = alpha, fill = ratio)) +
geom_tile(color = "white") +
scale_fill_gradient2(low = "blue", mid = "white", high = "red",
midpoint = 1,limits=c(0,2),
name = TeX("Empirical Rejection / $\\alpha$")) +
facet_wrap(~Method) +
labs(title = TeX(sprintf("Calibration Heatmaps for Multivariate-$t_\\nu(0,\\Sigma)$ with %s $\\Sigma$", cor.type)),
x = TeX("$\\nu$"), y = TeX("$\\alpha$")) +
theme_minimal(base_size = 13)
print(gg)
}
# Calibration heatmaps
calibration.heatmaps(n=1e6,d=10,nu.vec = c(0.1,0.5, 1, 5, 15, 30),
cor.type = "exch")
library(plyr)
library(MASS)
library(data.table)
library(latex2exp)
library(ggplot2)
library(gridExtra)
library(reshape2)
source("utils.R")
get.cor <- function(d, rho=0.5, cor.type="exch") {
stopifnot(cor.type %in% c("exch", "autoreg", "diag"))
if (cor.type=="exch") {
cor.mat <- matrix(rep(rho, d*d), nrow=d)
diag(cor.mat) <- 1
}
else if (cor.type=="autoreg") {
cor.mat <- rho^(abs(outer(1:d, 1:d, FUN="-")))
} else if (cor.type=="diag") {
cor.mat <- diag(d)
}
return(cor.mat)
}
o
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/utils.R", chdir = TRUE)
get.cor <- function(d, rho=0.5, cor.type="exch") {
stopifnot(cor.type %in% c("exch", "autoreg", "diag"))
if (cor.type=="exch") {
cor.mat <- matrix(rep(rho, d*d), nrow=d)
diag(cor.mat) <- 1
}
else if (cor.type=="autoreg") {
cor.mat <- rho^(abs(outer(1:d, 1:d, FUN="-")))
} else if (cor.type=="diag") {
cor.mat <- diag(d)
}
return(cor.mat)
}
# ----- Calibration Line Plot -----
calibration.lineplot <- function(nu.vec = c(1, 30),
alpha.vec = 10^seq(log10(0.001), log10(0.1), length.out = 100),
d = 10, n = 1e6,
cor.type = "autoreg") {
par(mfrow = c(1, length(nu.vec)), mar = c(4, 4, 3, 1), oma = c(0, 0, 4, 0))
for (nu in nu.vec) {
message(sprintf("Running nu = %f", nu))
cor.mat <- get.cor(d, cor.type = cor.type)
# simulate under null (mu = 0)
X <- mvrnorm(n = n, mu = rep(0, d), Sigma = cor.mat)
denom <- replicate(n, sqrt(rgamma(n=1,shape = nu/2,rate = 1/2)/nu))
X <- X / denom
pval <- 1 - pt(X, df = nu)
rejections <- t(sapply(alpha.vec, function(alpha) {
p.pareto <- combine.test(pval, method = "Pareto")
p.cauchy <- combine.test(pval, method = "Cauchy")
c(mean(p.pareto < alpha), mean(p.cauchy < alpha))
}))
ratio <- rejections / alpha.vec
plot(1 / alpha.vec, ratio[,1], type = "l", col = "red", ylim=c(0, max(ratio)),
xlab=TeX("$1/\\alpha$"), ylab="Empirical Rejection Rate / alpha",
main=TeX(sprintf("ν = %.2f", nu)))
lines(1 / alpha.vec, ratio[,2], type = "l", col = "blue")
abline(h = 1, lty = 2)
legend("bottomright", legend=c("PCT", "CCT"), col=c("red", "blue"), pch=1)
}
mtext(
TeX(sprintf("Calibration of PCT & CCT under Multivariate-$t_\\nu(0,\\Sigma)$ with %s $\\Sigma$", cor.type)),
outer = TRUE, cex = 1.5, line = 1
)
par(mfrow = c(1, 1))
}
# ----- Calibration Heatmaps -----
calibration.heatmaps <- function(alpha.vec = c( 0.05, 0.01, 0.005,0.001,0.0005,0.0001),
nu.vec = c(1, 5, 15, 30),
d = 10, n = 1e6,
cor.type = "autoreg") {
mat.pareto <- matrix(NA, nrow = length(alpha.vec), ncol = length(nu.vec))
mat.cauchy <- matrix(NA, nrow = length(alpha.vec), ncol = length(nu.vec))
for (i in seq_along(nu.vec)) {
nu <- nu.vec[i]
cor.mat <- get.cor(d, rho=0.5,cor.type = cor.type)
# simulate null
X <- mvrnorm(n = n, mu = rep(0, d), Sigma = cor.mat)
denom <- replicate(n, sqrt(rgamma(n=1,shape = nu/2,rate = 1/2)/nu))
X <- X / denom
pval <- 1 - pt(X, df = nu)
for (j in seq_along(alpha.vec)) {
alpha <- alpha.vec[j]
mat.pareto[j, i] <- mean(combine.test(pval, method = "Pareto") < alpha) / alpha
mat.cauchy[j, i] <- mean(combine.test(pval, method = "Cauchy") < alpha) / alpha
}
}
df.pareto <- as.data.frame(as.table(mat.pareto))
df.cauchy <- as.data.frame(as.table(mat.cauchy))
colnames(df.pareto) <- colnames(df.cauchy) <- c("alpha.idx", "nu.idx", "ratio")
df.pareto$Method <- "Pareto"
df.cauchy$Method <- "Cauchy"
df <- rbind(df.pareto, df.cauchy)
df$alpha <- factor(alpha.vec[df$alpha.idx], levels = rev(alpha.vec))
df$nu <- factor(nu.vec[df$nu.idx])
gg <- ggplot(df, aes(x = nu, y = alpha, fill = ratio)) +
geom_tile(color = "white") +
scale_fill_gradient2(low = "blue", mid = "white", high = "red",
midpoint = 1,limits=c(0,2),
name = TeX("Empirical Rejection / $\\alpha$")) +
facet_wrap(~Method) +
labs(title = TeX(sprintf("Calibration Heatmaps for Multivariate-$t_\\nu(0,\\Sigma)$ with %s $\\Sigma$", cor.type)),
x = TeX("$\\nu$"), y = TeX("$\\alpha$")) +
theme_minimal(base_size = 13)
print(gg)
}
# Calibration heatmaps
calibration.heatmaps(n=1e6,d=10,nu.vec = c(0.1,0.5, 1, 5, 15, 30),
cor.type = "exch")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
source("~/Downloads/MRV_Cauchy_n_Pareto/Code/simu_mvt_eigen.R")
tinytex::install_tinytex()
knitr::opts_chunk$set(
echo = TRUE,
message = FALSE,
warning = FALSE
)
set.seed(604)
options(digits = 16)
pval_exact <- choose(71, 46) * choose(26, 8) / choose(107, 54)
pval_exact
M_total <- 107   # total submissions
K_reject <- 71   # total rejections (successes)
n_negative <- 54 # size of "negative" group
x_obs <- 46      # observed rejections in the negative group
# One-sided (upper-tail) hypergeometric p-value: P[X >= 46]
pval_upper <- phyper(q = x_obs - 1, m = K_reject, n = M_total - K_reject,
k = n_negative, lower.tail = FALSE)
pval_upper
M_total <- 107   # total submissions
K_reject <- 71   # total rejections (successes)
n_negative <- 54 # size of "negative" group
x_obs <- 46      # observed rejections in the negative group
# One-sided (upper-tail) hypergeometric p-value: P[X >= 46]
pval_upper <- phyper(q = x_obs - 1, m = K_reject, n = M_total - K_reject,
k = n_negative, lower.tail = FALSE)
pval_upper
# Direct computation
prob <- choose(10, 5) / (2^10)
prob
# Data (paired times for A and B; Tr=1 means A treated in that pair)
dat <- data.frame(
A  = c(44, 48, 50, 49, 50, 57, 60, 51, 52, 45),
B  = c(49, 43, 58, 51, 52, 47, 54, 46, 40, 51),
Tr = c(1, 0, 1, 0, 1, 0, 0, 0, 0, 1)
)
# Difference-in-means function given an assignment vector Tr (0/1 per pair)
dfm <- function(A, B, Tr){
mean(A*Tr + B*(1 - Tr)) - mean(A*(1 - Tr) + B*Tr)
}
# Observed statistic
obs_dfm <- dfm(dat$A, dat$B, dat$Tr)
obs_dfm
# Data (paired times for A and B; Tr=1 means A treated in that pair)
dat <- data.frame(
A  = c(44, 48, 50, 49, 50, 57, 60, 51, 52, 45),
B  = c(49, 43, 58, 51, 52, 47, 54, 46, 40, 51),
Tr = c(1, 0, 1, 0, 1, 0, 0, 0, 0, 1)
)
# Difference-in-means function given an assignment vector Tr (0/1 per pair)
difff_mean <- function(A, B, Tr){
mean(A*Tr + B*(1 - Tr)) - mean(A*(1 - Tr) + B*Tr)
}
# Observed statistic
obs_dfm <- difff_mean(dat$A, dat$B, dat$Tr)
obs_dfm
# ----- Permutation distribution over all 2^10 assignments -----
permu_test <- expand.grid(rep(list(0:1), 10))
permu_dist <- numeric(nrow(permu_test))
for(i in 1:nrow(permu_test)){
Tr_i <- unlist(permu_test[i, ])
permu_dist[i] <- dfm(dat$A, dat$B, Tr_i)
}
# One-sided p-value: proportion at least as large as observed
pval_all <- mean(obs_dfm >= permu_dist)
pval_all
# Visualize the permutation distribution
hist(permu_dist, main = "Histogram of permutation distribution (all 2^10)",
xlab = "dfm", breaks = 20)
abline(v = obs_dfm, lwd = 2)
# Data (paired times for A and B; Tr=1 means A treated in that pair)
dat <- data.frame(
A  = c(44, 48, 50, 49, 50, 57, 60, 51, 52, 45),
B  = c(49, 43, 58, 51, 52, 47, 54, 46, 40, 51),
Tr = c(1, 0, 1, 0, 1, 0, 0, 0, 0, 1)
)
# Difference-in-means function given an assignment vector Tr (0/1 per pair)
diff_mean <- function(A, B, Tr){
mean(A*Tr + B*(1 - Tr)) - mean(A*(1 - Tr) + B*Tr)
}
# Observed statistic
obs_dfm <- diff_mean(dat$A, dat$B, dat$Tr)
obs_dfm
# ----- Permutation distribution over all 2^10 assignments -----
permu_test <- expand.grid(rep(list(0:1), 10))
permu_dist <- numeric(nrow(permu_test))
for(i in 1:nrow(permu_test)){
Tr_i <- unlist(permu_test[i, ])
permu_dist[i] <- diff_mean(dat$A, dat$B, Tr_i)
}
# One-sided p-value: proportion at least as large as observed
pval_all <- mean(obs_dfm >= permu_dist)
pval_all
# Visualize the permutation distribution
hist(permu_dist, main = "Histogram of permutation distribution (all 2^10)",
xlab = "dfm", breaks = 20)
abline(v = obs_dfm, lwd = 2)
# ----- Permutation distribution over all 2^10 assignments -----
permu_test <- expand.grid(rep(list(0:1), 10))
permu_dist <- numeric(nrow(permu_test))
for(i in 1:nrow(permu_test)){
Tr_i <- unlist(permu_test[i, ])
permu_dist[i] <- diff_mean(dat$A, dat$B, Tr_i)
}
# One-sided p-value: proportion at least as large as observed
pval_all <- mean(obs_dfm >= permu_dist)
pval_all
# Visualize the permutation distribution
hist(permu_dist, main = "Histogram of permutation distribution (all 2^10)",
xlab = "Difference in means", breaks = 20)
abline(v = obs_dfm, lwd = 2)
# Empirical CDF for the "all 2^10 assignments" null
ecdf_all <- ecdf(permu_dist)
plot(ecdf_all, do.points = FALSE, verticals = TRUE,
main = "Empirical CDF under null (all 2^10 assignments)",
xlab = "dfm", ylab = "F_n(x)")
abline(v = obs_dfm, lty = 2, lwd = 2)
text(x = obs_dfm, y = 0.05, labels = "observed dfm", pos = 4)
# Empirical CDF for the "all 2^10 assignments" null
ecdf_all <- ecdf(permu_dist)
plot(ecdf_all, do.points = FALSE, verticals = TRUE,
main = "Empirical CDF under null (all 2^10 assignments)",
xlab = "Difference in means", ylab = "F_n(x)")
abline(v = obs_dfm, lty = 2, lwd = 2)
text(x = obs_dfm, y = 0.05, labels = "observed dfm", pos = 4)
# ----- Permutation distribution over all 2^10 assignments -----
permu_test <- expand.grid(rep(list(0:1), 10))
permu_dist <- numeric(nrow(permu_test))
for(i in 1:nrow(permu_test)){
Tr_i <- unlist(permu_test[i, ])
permu_dist[i] <- diff_mean(dat$A, dat$B, Tr_i)
}
# One-sided p-value: proportion at least as large as observed
pval_all <- mean(obs_dfm >= permu_dist)
pval_all
# Visualize the permutation distribution
hist(permu_dist, main = "Histogram of permutation distribution (all 2^10)",
xlab = "Difference in means", breaks = 20)
abline(v = obs_dfm, lwd = 2)
# Empirical CDF for the "all 2^10 assignments" null
ecdf_all <- ecdf(permu_dist)
plot(ecdf_all, do.points = FALSE, verticals = TRUE,
main = "Empirical CDF under null (all 2^10 assignments)",
xlab = "Difference in means", ylab = "F_n(x)")
abline(v = obs_dfm, lty = 2, lwd = 2)
text(x = obs_dfm, y = 0.05, labels = "observed dfm", pos = 4)
source("~/.active-rstudio-document")
blockAcombos = matrix(combn(4,1),,4)
blockBcombos = combn(4,3) + 4
blockAcombos
blockBcombos
source("~/Documents/GitHub/Universal-Calibration-of-PCTs/calibration - heavy-tailed tests/calibration.R")
source("~/Documents/GitHub/Universal-Calibration-of-PCTs/calibration - heavy-tailed tests/calibration.R")
source("~/Documents/GitHub/Universal-Calibration-of-PCTs/calibration - heavy-tailed tests/calibration.R")
source("~/Documents/GitHub/Universal-Calibration-of-PCTs/calibration - heavy-tailed tests/calibration.R")
source("~/Documents/GitHub/Universal-Calibration-of-PCTs/calibration - heavy-tailed tests/calibration.R")
source("~/Documents/GitHub/Universal-Calibration-of-PCTs/calibration - heavy-tailed tests/calibration.R")
source("~/Documents/GitHub/Universal-Calibration-of-PCTs/calibration - heavy-tailed tests/calibration.R")
